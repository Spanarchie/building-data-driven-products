{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from collections import Counter\n",
    "from gensim import utils\n",
    "from gensim.models import doc2vec\n",
    "from nltk.corpus import stopwords\n",
    "from pydocumentdb import document_client\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COSMOSDB_ENDPOINT = '<Your Cosmos DB endpoint>'\n",
    "COSMOSDB_KEY = '<Your Cosmos DB "primaryMasterKey">'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = document_client.DocumentClient(COSMOSDB_ENDPOINT, {'masterKey': COSMOSDB_KEY})\n",
    "db = next(x for x in client.ReadDatabases() if x['id'] == 'ted')\n",
    "coll = next(x for x in client.ReadCollections(db['_self']) if x['id'] == 'talks')\n",
    "query_talks = lambda q: list(client.QueryDocuments(coll['_self'], {'query': q}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_talks = query_talks('SELECT * FROM talks t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transcript for the first talk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_talks[0]['transcript']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract and join text only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' '.join([x['text'].replace('\\n', ' ') for x in all_talks[0]['transcript']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 20 lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_counter = Counter(line['text'] for talk in all_talks for line in talk.get('transcript', []))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_counter.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract all \"comments\" (in round brackets) and find the most common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_transcripts_joined = ' '.join(\n",
    "    ' '.join(line['text'].replace('\\n', ' ') for line in talk.get('transcript', []))\n",
    "    for talk in all_talks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_counter = Counter(re.findall(r'(\\(.+?\\))', all_transcripts_joined))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_counter.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract all transcripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_transcripts = [\n",
    "    (talk['id'], ' '.join(line['text'].replace('\\n', ' ') for line in talk.get('transcript', [])))\n",
    "    for talk in all_talks\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter out talks with no transcript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_transcripts = [(talk_id, transcript)\n",
    "                   for talk_id, transcript in all_transcripts\n",
    "                   if len(transcript) != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(all_transcripts, key=lambda x: len(x[1]))[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter out music."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_transcripts = [(talk_id, transcript)\n",
    "                   for talk_id, transcript in all_transcripts\n",
    "                   if '(Music)' not in transcript and '(Music ends)' not in transcript]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(all_transcripts, key=lambda x: len(x[1]))[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost there..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_transcripts = [(talk_id, transcript)\n",
    "                   for talk_id, transcript in all_transcripts\n",
    "                   if 'â™«' not in transcript]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(all_transcripts, key=lambda x: len(x[1]))[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove all \"comments\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_re = '|'.join([k.replace('(', '\\(').replace(')', '\\)') for k, v in comment_counter.most_common(20)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_transcripts = [\n",
    "    (talk_id, re.sub(comment_re, ' ', transcript))\n",
    "    for talk_id, transcript in all_transcripts\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to extract words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_stopwords = set(stopwords.words('english'))\n",
    "\n",
    "def extract_words(text):\n",
    "    text = re.sub(r'[^A-Za-z/\\'\\-]', ' ', text)\n",
    "    text = [utils.to_unicode(w)\n",
    "            for w in text.lower().split()\n",
    "            if w not in english_stopwords]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_words(all_transcripts[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list of `TaggedDocument`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_docs = [\n",
    "    doc2vec.TaggedDocument(extract_words(transcript), [talk_id])\n",
    "    for talk_id, transcript in all_transcripts\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define and train a Doc2Vec model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = doc2vec.Doc2Vec(\n",
    "    documents=tagged_docs,\n",
    "    epochs=100,\n",
    "    min_count=2,\n",
    "    seed=42,\n",
    "    vector_size=100,\n",
    "    window=10,\n",
    "    workers=8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to retrieve the title of a talk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_title = lambda talk_id: next(x['title'] for x in all_talks if x['id'] == str(talk_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to retrieve the `n` most similar talks to a given talk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar(talk_id, n=10):\n",
    "    return pd.DataFrame([\n",
    "        (similar_id, get_title(similar_id), similarity)\n",
    "        for similar_id, similarity in model.docvecs.most_similar([str(talk_id)], topn=n)\n",
    "    ], columns=['id', 'title', 'similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_title('2337')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar('2337')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing model results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to compute all pairwise similarities for a given talk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "talk_ids = [talk_id for talk_id, _ in all_transcripts]\n",
    "\n",
    "def similarities(talk_id):\n",
    "    distances = model.docvecs.distances(talk_id)\n",
    "    return [\n",
    "        (id_, float(similarity))\n",
    "        for id_, similarity in zip(talk_ids, 1 - distances)\n",
    "        if id_ != talk_id\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities('2337')[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list of documents to upload to Cosmos DB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_docs = [\n",
    "    {\n",
    "        'id': talk_id,\n",
    "        'similarities': [{\n",
    "            'other_id': other_talk_id,\n",
    "            'similarity': similarity,\n",
    "        } for other_talk_id, similarity in similarities(talk_id)],\n",
    "    }\n",
    "    for talk_id in talk_ids\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new Cosmos DB collection for the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities_coll = next((x for x in client.ReadCollections(db['_self'])\n",
    "                          if x['id'] == 'similarities'), None)\n",
    "\n",
    "if similarities_coll:\n",
    "    client.DeleteCollection(similarities_coll['_self'])\n",
    "\n",
    "similarities_coll = client.CreateCollection(db['_self'], {'id': 'similarities'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload documents to Cosmos DB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in similarity_docs:\n",
    "    client.CreateDocument(similarities_coll['_self'], doc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
